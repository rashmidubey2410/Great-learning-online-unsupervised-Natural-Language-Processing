{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# IMPORT DATA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = 'C:/Users/test/Desktop/GL 2018.09.29/'\n",
    "data = pd.read_csv(path + 'ner_dataset.csv', encoding='latin1')\n",
    "data = data.fillna(method=\"ffill\") # Deal with N/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(set(data[\"POS\"].values)) # Read POS values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VBG',\n",
       " 'RBS',\n",
       " 'DT',\n",
       " 'MD',\n",
       " 'PDT',\n",
       " 'RP',\n",
       " '$',\n",
       " '``',\n",
       " 'PRP',\n",
       " 'RRB',\n",
       " 'VBN',\n",
       " 'VBP',\n",
       " 'NN',\n",
       " ':',\n",
       " 'CC',\n",
       " 'NNPS',\n",
       " 'UH',\n",
       " 'IN',\n",
       " 'RBR',\n",
       " 'VBD',\n",
       " 'NNP',\n",
       " 'JJS',\n",
       " 'WP',\n",
       " 'RB',\n",
       " 'WDT',\n",
       " 'EX',\n",
       " ';',\n",
       " 'LRB',\n",
       " 'NNS',\n",
       " 'VB',\n",
       " 'POS',\n",
       " 'PRP$',\n",
       " ',',\n",
       " 'JJR',\n",
       " 'WP$',\n",
       " 'WRB',\n",
       " 'FW',\n",
       " 'JJ',\n",
       " 'VBZ',\n",
       " 'TO',\n",
       " '.',\n",
       " 'CD']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags # List of possible POS values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"DUMMY\") # Add a dummy word to pad sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to read sentences\n",
    "\n",
    "class ReadSentences(object): \n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ReadSentences(data).sentences # Read all sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert words and tags into numbers\n",
    "word2id = {w: i for i, w in enumerate(words)}\n",
    "tag2id = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\test\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Prepare input and output data\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_len = 50\n",
    "X = [[word2id[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=len(words)-1)\n",
    "y = [[tag2id[w[1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2id[\".\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert output to one-hot bit\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=len(tags)) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and test split by sentences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(max_len,)) # Input layer\n",
    "model = Embedding(input_dim=len(words), output_dim=50, input_length=max_len)(input) # Word embedding layer\n",
    "model = Dropout(0.1)(model) # Dropout\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model) # Bi-directional LSTM layer\n",
    "out = TimeDistributed(Dense(len(tags), activation=\"softmax\"))(model)  # softmax output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input, out) # Complete model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]) # Compile with an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34530 samples, validate on 3837 samples\n",
      "Epoch 1/3\n",
      "34530/34530 [==============================] - 82s 2ms/step - loss: 0.3857 - acc: 0.8957 - val_loss: 0.0663 - val_acc: 0.9807\n",
      "Epoch 2/3\n",
      "34530/34530 [==============================] - 80s 2ms/step - loss: 0.0488 - acc: 0.9858 - val_loss: 0.0428 - val_acc: 0.9869\n",
      "Epoch 3/3\n",
      "34530/34530 [==============================] - 80s 2ms/step - loss: 0.0335 - acc: 0.9901 - val_loss: 0.0366 - val_acc: 0.9888\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, np.array(y_tr), batch_size=32, epochs=3, validation_split=0.1, verbose=1) # Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports              -- NNS\n",
      "of                   -- IN\n",
      "the                  -- DT\n",
      "types                -- NNS\n",
      "of                   -- IN\n",
      "watches              -- NNS\n",
      "that                 -- IN\n",
      "now                  -- RB\n",
      "will                 -- MD\n",
      "be                   -- VB\n",
      "eligible             -- JJ\n",
      "for                  -- IN\n",
      "duty-free            -- JJ\n",
      "treatment            -- NN\n",
      "totaled              -- VBD\n",
      "about                -- IN\n",
      "$                    -- $\n",
      "37.3                 -- CD\n",
      "million              -- CD\n",
      "in                   -- IN\n",
      "1988                 -- CD\n",
      ",                    -- ,\n",
      "a                    -- DT\n",
      "relatively           -- RB\n",
      "small                -- JJ\n",
      "share                -- NN\n",
      "of                   -- IN\n",
      "the                  -- DT\n",
      "$                    -- $\n",
      "1.5                  -- CD\n",
      "billion              -- CD\n",
      "in                   -- IN\n",
      "U.S.                 -- NNP\n",
      "watch                -- NN\n",
      "imports              -- NNS\n",
      "that                 -- WDT\n",
      "year                 -- NN\n",
      ",                    -- ,\n",
      "according            -- VBG\n",
      "to                   -- TO\n",
      "an                   -- DT\n",
      "aide                 -- NN\n",
      "to                   -- TO\n",
      "U.S.                 -- NNP\n",
      "Trade                -- NNP\n",
      "Representative       -- NNP\n",
      "Carla                -- NNP\n",
      "Hills                -- NNP\n",
      ".                    -- .\n",
      "DUMMY                -- .\n"
     ]
    }
   ],
   "source": [
    "# Demo test on one sample. See how it is mostly correct, but not 100%\n",
    "\n",
    "i = 1213 # Some test sentence sample\n",
    "p = model.predict(np.array([X_te[i]])) # Predict on it\n",
    "p = np.argmax(p, axis=-1) # Map softmax back to a POS index\n",
    "for w, pred in zip(X_te[i], p[0]): # for every word in the sentence\n",
    "    print(\"{:20} -- {}\".format(words[w], tags[pred])) # Print word and tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "sentence = nltk.word_tokenize('That was a nice jump')\n",
    "X_Samp = pad_sequences(maxlen=max_len, sequences=[[word2id[word] for word in sentence]], padding=\"post\", value=len(words)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That                 -- DT\n",
      "was                  -- VBD\n",
      "a                    -- DT\n",
      "nice                 -- JJ\n",
      "jump                 -- NN\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(np.array([X_Samp[0]])) # Predict on it\n",
    "p = np.argmax(p, axis=-1) # Map softmax back to a POS index\n",
    "for w, pred in zip(X_Samp[0], p[0]): # for every word in the sentence\n",
    "    print(\"{:20} -- {}\".format(words[w], tags[pred])) # Print word and tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
